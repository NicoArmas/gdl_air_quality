{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tsl.nn.layers.graph_convs import GatedGraphNetwork\n",
    "from tsl.nn.layers.temporal_attention import TemporalSelfAttention\n",
    "from tsl.nn.utils.utils import get_functional_activation\n",
    "from tsl.nn.blocks.encoders.mlp import MLP\n",
    "\n",
    "\n",
    "\n",
    "class SpatialModel(GatedGraphNetwork):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SpatialModel, self).__init__(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, x, edge_index, mask=None):\n",
    "        out = self.propagate(edge_index, x=x, mask=mask)\n",
    "        out = self.update_mlp(torch.cat([out, x], -1)) + self.skip_conn(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, mask_j):  # chiedere a marco come funziona questo!\n",
    "        mij = self.msg_mlp(torch.cat([x_i, x_j], -1))\n",
    "        return self.gate_mlp(mij) * mij\n",
    "\n",
    "\n",
    "class AirQualityModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 window_size,\n",
    "                 horizon,\n",
    "                 num_heads=8,\n",
    "                 n_sp_layers=5,\n",
    "                 n_tp_layers=1):\n",
    "\n",
    "        super(AirQualityModel, self).__init__()\n",
    "\n",
    "        # quello che (in teoria serve ai nostri layer)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = input_size\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.horizon = horizon\n",
    "\n",
    "        self.n_sp_layers = n_sp_layers\n",
    "        self.n_tp_layers = n_tp_layers\n",
    "\n",
    "        self.activation = get_functional_activation('relu')\n",
    "        self.upscale = nn.Linear(self.input_size, self.hidden_size)\n",
    "\n",
    "        #spatial layers 1\n",
    "        self.spatialSeq1 = nn.ModuleList()\n",
    "        for _ in range(self.n_sp_layers):\n",
    "            self.spatialSeq1.append(SpatialModel(self.hidden_size))\n",
    "\n",
    "        # temporal layers\n",
    "        self.temporalSeq = nn.ModuleList()\n",
    "        for _ in range(self.n_tp_layers):\n",
    "            self.temporalSeq.append(TemporalSelfAttention(self.hidden_size, self.num_heads))\n",
    "\n",
    "        # spatial layers 2\n",
    "        self.spatialSeq2 = nn.ModuleList()\n",
    "        for _ in range(self.n_sp_layers):\n",
    "            self.spatialSeq2.append(SpatialModel(self.hidden_size))\n",
    "\n",
    "        self.augmented_size = self.hidden_size + self.input_size\n",
    "\n",
    "        self.conv_layer = nn.Conv2d(self.window_size, self.horizon, 1)\n",
    "        self.output_layer = MLP(self.augmented_size, self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x, edge_index=None, **kwargs):\n",
    "        \"\"\"\n",
    "        The function takes in a 4D tensor (x) and returns a 4D tensor (output)\n",
    "        \n",
    "        :param x: [batch size, timestep, nodes, channels]\n",
    "        :param edge_index: [2, num_edges]\n",
    "        :return: The output of the model.\n",
    "        \"\"\"\n",
    "        # x: [batch size, timestep, nodes, channels]\n",
    "        input = self.upscale(x)\n",
    "        input = self.activation(input)\n",
    "\n",
    "        for i in range(self.n_sp_layers):\n",
    "            input = self.spatialSeq1[i](input, edge_index)\n",
    "\n",
    "        input = self.activation(input)\n",
    "\n",
    "        for i in range(self.n_tp_layers):\n",
    "            input, _ = self.temporalSeq[i](input)\n",
    "\n",
    "        for i in range(self.n_sp_layers):\n",
    "            input = self.spatialSeq2[i](input, edge_index)\n",
    "\n",
    "        input = self.activation(input)\n",
    "\n",
    "        input = torch.cat([input, x], dim=-1)\n",
    "        output = self.conv_layer(input)\n",
    "        output = self.output_layer(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "logger = TensorBoardLogger(save_dir=\"./tensorboard\", name=\"prova\", version=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 8427), started 0:21:25 ago. (Use '!kill 8427' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a9a79edadc0d5602\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a9a79edadc0d5602\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found temporal data pickle, loading...\tDONE!\n",
      "Found a valid build, loading... \tDONE!\n",
      "2022-05-17 10:43:15,940 [INFO]: Inferred input data-format: [steps, nodes, channels]\n",
      "2022-05-17 10:43:15,941 [INFO]: Inferred input data-format: [steps, nodes, channels]\n",
      "(3, 6, 9, 12)\n",
      "2022-05-17 10:43:19,656 [INFO]: Scaler for data: StandardScaler(bias=(1, 1, 1), scale=(1, 1, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/utilities/parsing.py:244: UserWarning: Attribute 'loss_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_fn'])`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-17 10:43:19,862 [INFO]: Scaler for data: StandardScaler(bias=(1, 1, 1), scale=(1, 1, 1))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory /home/lorenzo/PycharmProjects/gdl_air_quality/code/logs exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE        | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | test_metrics  | MetricCollection | 0     \n",
      "4 | model         | AirQualityModel  | 53.0 K\n",
      "---------------------------------------------------\n",
      "53.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "53.0 K    Total params\n",
      "0.212     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:00<00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   4%|▍         | 175/4378 [00:42<16:52,  4.15it/s, loss=3.67, v_num=3]{'mae': MaskedMAE()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/trainer/trainer.py:727: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lorenzo/PycharmProjects/gdl_air_quality/code/model_analysis.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lorenzo/PycharmProjects/gdl_air_quality/code/model_analysis.ipynb#ch0000001?line=85'>86</a>\u001b[0m trainer\u001b[39m.\u001b[39mfit(predictor, datamodule\u001b[39m=\u001b[39mdm)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lorenzo/PycharmProjects/gdl_air_quality/code/model_analysis.ipynb#ch0000001?line=87'>88</a>\u001b[0m \u001b[39mprint\u001b[39m(metrics)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/lorenzo/PycharmProjects/gdl_air_quality/code/model_analysis.ipynb#ch0000001?line=89'>90</a>\u001b[0m predictor\u001b[39m.\u001b[39;49mload_model(checkpoint_callback\u001b[39m.\u001b[39;49mbest_model_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lorenzo/PycharmProjects/gdl_air_quality/code/model_analysis.ipynb#ch0000001?line=90'>91</a>\u001b[0m predictor\u001b[39m.\u001b[39mfreeze()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/lorenzo/PycharmProjects/gdl_air_quality/code/model_analysis.ipynb#ch0000001?line=92'>93</a>\u001b[0m performance \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mtest(predictor, datamodule\u001b[39m=\u001b[39mdm)\n",
      "File \u001b[0;32m~/anaconda3/envs/GDL/lib/python3.9/site-packages/torch_spatiotemporal-0.1.0-py3.9.egg/tsl/predictors/base_predictor.py:82\u001b[0m, in \u001b[0;36mPredictor.load_model\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch_spatiotemporal-0.1.0-py3.9.egg/tsl/predictors/base_predictor.py?line=80'>81</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\u001b[39mself\u001b[39m, filename: \u001b[39mstr\u001b[39m):\n\u001b[0;32m---> <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch_spatiotemporal-0.1.0-py3.9.egg/tsl/predictors/base_predictor.py?line=81'>82</a>\u001b[0m     model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(filename, \u001b[39mlambda\u001b[39;49;00m storage, loc: storage)\n\u001b[1;32m     <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch_spatiotemporal-0.1.0-py3.9.egg/tsl/predictors/base_predictor.py?line=82'>83</a>\u001b[0m     model_cls, model_kwargs \u001b[39m=\u001b[39m model[\u001b[39m'\u001b[39m\u001b[39mhyper_parameters\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmodel_class\u001b[39m\u001b[39m'\u001b[39m], \\\n\u001b[1;32m     <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch_spatiotemporal-0.1.0-py3.9.egg/tsl/predictors/base_predictor.py?line=83'>84</a>\u001b[0m                               model[\u001b[39m'\u001b[39m\u001b[39mhyper_parameters\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmodel_kwargs\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch_spatiotemporal-0.1.0-py3.9.egg/tsl/predictors/base_predictor.py?line=84'>85</a>\u001b[0m     \u001b[39massert\u001b[39;00m model_cls \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_cls\n",
      "File \u001b[0;32m~/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=695'>696</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=696'>697</a>\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=698'>699</a>\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=699'>700</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=700'>701</a>\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=701'>702</a>\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=702'>703</a>\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=703'>704</a>\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=228'>229</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=229'>230</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=230'>231</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=231'>232</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=232'>233</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=210'>211</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> <a href='file:///home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/serialization.py?line=211'>212</a>\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "\n",
    "import tsl\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from airquality import AirQuality as AQ\n",
    "dataset =AQ(is_subgraph=True, sub_start='6.0-73.0-1201.0', sub_size=100, data_dir='../data')\n",
    "\n",
    "adj = dataset.get_connectivity(threshold=0.1,\n",
    "                                include_self=False,\n",
    "                                normalize_axis=1,\n",
    "                                layout=\"edge_index\")\n",
    "\n",
    "from tsl.data import SpatioTemporalDataset\n",
    "\n",
    "torch_dataset = SpatioTemporalDataset(*dataset.numpy(return_idx=True),\n",
    "                                        connectivity=adj,\n",
    "                                        mask=dataset.mask,\n",
    "                                        horizon=1,  # li metto gia da qui?\n",
    "                                        window=12)  # li metto gia da qui? era 12\n",
    "\n",
    "\n",
    "from tsl.data import SpatioTemporalDataModule\n",
    "from tsl.data.preprocessing import StandardScaler\n",
    "\n",
    "scalers = {'data': StandardScaler(axis=(0, 1))}\n",
    "\n",
    "splitter = dataset.get_splitter(val_len=0.1, test_len=0.2)\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=4,  # era 64!\n",
    ")\n",
    "\n",
    "dm.setup()\n",
    "\n",
    "from tsl.nn.metrics.metrics import MaskedMAE, MaskedMAPE\n",
    "from tsl.predictors import Predictor\n",
    "\n",
    "loss_fn = MaskedMAE(compute_on_step=True)\n",
    "\n",
    "metrics = {'mae': MaskedMAE(compute_on_step=False)}\n",
    "            #'mape': MaskedMAPE(compute_on_step=False)}\n",
    "            #'mae_at_15': MaskedMAE(compute_on_step=False, at=2),  # `2` indicated the third time step,\n",
    "            # which correspond to 15 minutes ahead\n",
    "            #'mae_at_30': MaskedMAE(compute_on_step=False, at=5),\n",
    "            #'mae_at_60': MaskedMAE(compute_on_step=False, at=11), }\n",
    "\n",
    "model_kwargs = {\n",
    "    'input_size': 1,\n",
    "    'hidden_size': 32,\n",
    "    # era trentadue ma non andava per la divisibilita probabilemnte ce un problema con input_size_sp era 31\n",
    "    'window_size': 12,  # era 12\n",
    "    'horizon': 1\n",
    "}\n",
    "\n",
    "# setup predictor\n",
    "predictor = Predictor(\n",
    "    model_class=AirQualityModel,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    optim_kwargs={'lr': 0.001},  # 0.001\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='logs',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=3,\n",
    "                        gpus=1 if torch.cuda.is_available() else None,\n",
    "                        #logger=logger,\n",
    "                        # limit_train_batches=100,\n",
    "                        callbacks=[checkpoint_callback])\n",
    "\n",
    "\n",
    "trainer.fit(predictor, datamodule=dm)\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "predictor.load_model(checkpoint_callback.best_model_path)\n",
    "predictor.freeze()\n",
    "\n",
    "performance = trainer.test(predictor, datamodule=dm)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "680e81d386bdd33f7a9a9653c5e155acb4122dc6ba1be0a86a256d82ab40669b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('GDL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
