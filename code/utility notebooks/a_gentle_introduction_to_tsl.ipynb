{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TorchSpatiotemporal/tsl/blob/main/examples/notebooks/a_gentle_introduction_to_tsl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xxE1lI-YVk2"
      },
      "source": [
        "# A Gentle Introduction to tsl\n",
        "---\n",
        "\n",
        "This a tutorial notebook about __tsl (Torch Spatiotemporal)__, a Python library built upon the PyTorch ecosystem\n",
        "and tailored for spatiotemporal data processing.\n",
        "\n",
        "In this notebook we are going to see what are the necessary steps from data loading to model training.\n",
        "\n",
        "## Installation\n",
        "---\n",
        "\n",
        "Let's start by the installation. If you run the notebook in colab, you can install tsl with these commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJwaWoSrYVk3"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/TorchSpatiotemporal/tsl.git\n",
        "!pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-1.10.1+cu113.html\n",
        "!pip install ./tsl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "ZxoqCutTYVk4"
      },
      "source": [
        "In particular, the second command is installing `torch-geometric` dependencies for the specific environment you have on colab with GPU runtime. Please refer to [PyG installation guidelines](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html) for installation in other environments.\n",
        "\n",
        "We recommend to install tsl from GitHub repository at the moment, to be sure you are up-to-date with latest version.\n",
        "\n",
        "Let's check if everything is ok."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLAxpbejYVk4"
      },
      "outputs": [],
      "source": [
        "import tsl\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "np.set_printoptions(suppress=True)\n",
        "tsl.logger.disabled = True\n",
        "\n",
        "print(f\"tsl version  : {tsl.__version__}\")\n",
        "print(f\"torch version: {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "D_bK40BaYVk5"
      },
      "source": [
        "## Usage\n",
        "---\n",
        "\n",
        "tsl is more than a collection of layers. We can classify the library modules into:\n",
        "\n",
        "* __Data loading modules__\n",
        "    Manage how to store, preprocess and visualize spatio-temporal data\n",
        "* __Inference modules__\n",
        "    Methods and models exploiting the data to make inferences\n",
        "\n",
        "We will go deeper on them in next sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wy4OORcYVk5"
      },
      "source": [
        "## Data loading\n",
        "---\n",
        "\n",
        "`tsl` comes with several datasets used in spatiotemporal processing literature. You can find them inside the submodule `tsl.datasets`.\n",
        "\n",
        "### Loading the dataset\n",
        "\n",
        "As an example, we start by using the [MetrLA](https://paperswithcode.com/sota/traffic-prediction-on-metr-la) dataset, a common benchmark for traffic forecasting. The dataset contains traffic readings collected from 207 loop detectors on highways in Los Angeles County, aggregated in 5 minute intervals for 4 months between March 2012 to June 2012. Loading the dataset is as simple as that:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BsPkG4uMYVk5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found a valid build, loading... \tDONE!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Python310\\lib\\site-packages\\tsl\\datasets\\prototypes\\checks.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, float_cols] = df[float_cols].astype(to_dtype)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AQ(length=17526, n_nodes=100, n_channels=1)\n"
          ]
        }
      ],
      "source": [
        "from airquality import AirQuality\n",
        "\n",
        "dataset = AirQuality(is_subgraph=True, sub_start='6.0-73.0-1201.0', sub_size=100, data_dir='../data')\n",
        "\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67IyIupLYVk6"
      },
      "source": [
        "We can see that data are organized a 3-dimensional array, with:\n",
        "\n",
        "* 34.272 temporal steps (1 each 5 minute for 4 months)\n",
        "* 207 nodes (the loop detectors)\n",
        "* 1 channels (detected speed)\n",
        "\n",
        "Nice! Other than storing the data of interest, the dataset comes with useful tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L74iikTiYVk6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sampling period: <5 * Minutes>\n",
            "Has missing values: True\n",
            "Percentage of missing values: 8.11%\n",
            "Has dataset exogenous variables: False\n",
            "Relevant attributes: dist\n"
          ]
        }
      ],
      "source": [
        "print(f\"Sampling period: {dataset.freq}\\n\"\n",
        "      f\"Has missing values: {dataset.has_mask}\\n\"\n",
        "      f\"Percentage of missing values: {(1 - dataset.mask.mean()) * 100:.2f}%\\n\"\n",
        "      f\"Has dataset exogenous variables: {dataset.has_exogenous}\\n\"\n",
        "      f\"Relevant attributes: {', '.join(dataset.attributes.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC8LfuK4YVk6"
      },
      "source": [
        "Let's look at the output. We know that the dataset has missing entries, with `dataset.mask` being a binary indicator associated with each timestep, node and channel (with ones indicating valid values).\n",
        "\n",
        "Also, the dataset has no exogenous variables, i.e., there are no time-varying features paired with the main signal.\n",
        "Instead it has a useful attribute: the distance matrix. We call *attributes*, features that are static.\n",
        "\n",
        "You can access exogenous variables and attributes by `dataset.name`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_YgmDUtWYVk7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[    0.      inf     inf ...     inf  8114.8 10009.7]\n",
            " [    inf     0.   2504.6 ...     inf     inf     inf]\n",
            " [    inf  1489.3     0.  ...     inf     inf  9837. ]\n",
            " ...\n",
            " [    inf     inf     inf ...     0.      inf     inf]\n",
            " [ 9599.8     inf     inf ...     inf     0.      inf]\n",
            " [10119.9  9374.8     inf ...     inf  9018.7     0. ]]\n"
          ]
        }
      ],
      "source": [
        "print(dataset.dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1uMQREKYVk7"
      },
      "source": [
        "This matrix stores the pairwise distance between sensors, with `inf` denoting two non-neighboring sensors.\n",
        "\n",
        "Let's now check how the speed readings look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hxqyccSSYVk7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>nodes</th>\n",
              "      <th>32.0-3.0-1019.0</th>\n",
              "      <th>32.0-3.0-1501.0</th>\n",
              "      <th>32.0-3.0-298.0</th>\n",
              "      <th>32.0-3.0-43.0</th>\n",
              "      <th>32.0-3.0-540.0</th>\n",
              "      <th>32.0-3.0-561.0</th>\n",
              "      <th>32.0-3.0-75.0</th>\n",
              "      <th>32.0-3.0-8000.0</th>\n",
              "      <th>32.0-31.0-25.0</th>\n",
              "      <th>32.0-5.0-7.0</th>\n",
              "      <th>...</th>\n",
              "      <th>6.0-85.0-5.0</th>\n",
              "      <th>6.0-85.0-6.0</th>\n",
              "      <th>6.0-87.0-1005.0</th>\n",
              "      <th>6.0-87.0-7.0</th>\n",
              "      <th>6.0-9.0-1.0</th>\n",
              "      <th>6.0-95.0-4.0</th>\n",
              "      <th>6.0-99.0-5.0</th>\n",
              "      <th>6.0-99.0-6.0</th>\n",
              "      <th>80.0-2.0-12.0</th>\n",
              "      <th>80.0-2.0-14.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>channels</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>...</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "      <th>PM25</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DateTime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-01-01 04:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 05:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 06:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 07:00:00</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 08:00:00</th>\n",
              "      <td>2.4</td>\n",
              "      <td>89.800003</td>\n",
              "      <td>23.200001</td>\n",
              "      <td>14.9</td>\n",
              "      <td>153.699997</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.2</td>\n",
              "      <td>5.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>28.0</td>\n",
              "      <td>...</td>\n",
              "      <td>101.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>43.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>622.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 09:00:00</th>\n",
              "      <td>2.7</td>\n",
              "      <td>92.400002</td>\n",
              "      <td>22.700001</td>\n",
              "      <td>11.4</td>\n",
              "      <td>152.399994</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.7</td>\n",
              "      <td>4.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.0</td>\n",
              "      <td>...</td>\n",
              "      <td>81.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>45.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>744.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 10:00:00</th>\n",
              "      <td>2.6</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>14.200000</td>\n",
              "      <td>8.1</td>\n",
              "      <td>114.900002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.8</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12.0</td>\n",
              "      <td>...</td>\n",
              "      <td>63.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>278.0</td>\n",
              "      <td>678.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 11:00:00</th>\n",
              "      <td>2.7</td>\n",
              "      <td>51.299999</td>\n",
              "      <td>11.100000</td>\n",
              "      <td>6.4</td>\n",
              "      <td>179.199997</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2.9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.0</td>\n",
              "      <td>...</td>\n",
              "      <td>58.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>688.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 12:00:00</th>\n",
              "      <td>3.0</td>\n",
              "      <td>38.500000</td>\n",
              "      <td>8.600000</td>\n",
              "      <td>5.5</td>\n",
              "      <td>108.599998</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>...</td>\n",
              "      <td>60.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>789.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-01 13:00:00</th>\n",
              "      <td>3.3</td>\n",
              "      <td>30.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>5.5</td>\n",
              "      <td>94.800003</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.1</td>\n",
              "      <td>2.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>...</td>\n",
              "      <td>55.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>31.0</td>\n",
              "      <td>51.0</td>\n",
              "      <td>297.0</td>\n",
              "      <td>809.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "nodes               32.0-3.0-1019.0 32.0-3.0-1501.0 32.0-3.0-298.0  \\\n",
              "channels                       PM25            PM25           PM25   \n",
              "DateTime                                                             \n",
              "2018-01-01 04:00:00             NaN             NaN            NaN   \n",
              "2018-01-01 05:00:00             NaN             NaN            NaN   \n",
              "2018-01-01 06:00:00             NaN             NaN            NaN   \n",
              "2018-01-01 07:00:00             NaN             NaN            NaN   \n",
              "2018-01-01 08:00:00             2.4       89.800003      23.200001   \n",
              "2018-01-01 09:00:00             2.7       92.400002      22.700001   \n",
              "2018-01-01 10:00:00             2.6       73.000000      14.200000   \n",
              "2018-01-01 11:00:00             2.7       51.299999      11.100000   \n",
              "2018-01-01 12:00:00             3.0       38.500000       8.600000   \n",
              "2018-01-01 13:00:00             3.3       30.400000       6.900000   \n",
              "\n",
              "nodes               32.0-3.0-43.0 32.0-3.0-540.0 32.0-3.0-561.0 32.0-3.0-75.0  \\\n",
              "channels                     PM25           PM25           PM25          PM25   \n",
              "DateTime                                                                        \n",
              "2018-01-01 04:00:00           NaN            NaN            NaN           NaN   \n",
              "2018-01-01 05:00:00           NaN            NaN            NaN           NaN   \n",
              "2018-01-01 06:00:00           NaN            NaN            NaN           NaN   \n",
              "2018-01-01 07:00:00           NaN            NaN            NaN           NaN   \n",
              "2018-01-01 08:00:00          14.9     153.699997            NaN           6.2   \n",
              "2018-01-01 09:00:00          11.4     152.399994            NaN           5.7   \n",
              "2018-01-01 10:00:00           8.1     114.900002            NaN           4.8   \n",
              "2018-01-01 11:00:00           6.4     179.199997            NaN           3.9   \n",
              "2018-01-01 12:00:00           5.5     108.599998            NaN           5.0   \n",
              "2018-01-01 13:00:00           5.5      94.800003            NaN           5.1   \n",
              "\n",
              "nodes               32.0-3.0-8000.0 32.0-31.0-25.0 32.0-5.0-7.0  ...  \\\n",
              "channels                       PM25           PM25         PM25  ...   \n",
              "DateTime                                                         ...   \n",
              "2018-01-01 04:00:00             NaN            NaN          NaN  ...   \n",
              "2018-01-01 05:00:00             NaN            NaN          NaN  ...   \n",
              "2018-01-01 06:00:00             NaN            NaN          NaN  ...   \n",
              "2018-01-01 07:00:00             NaN            NaN          NaN  ...   \n",
              "2018-01-01 08:00:00             5.6            NaN         28.0  ...   \n",
              "2018-01-01 09:00:00             4.3            NaN         26.0  ...   \n",
              "2018-01-01 10:00:00             3.0            NaN         12.0  ...   \n",
              "2018-01-01 11:00:00             2.9            NaN         16.0  ...   \n",
              "2018-01-01 12:00:00             1.5            NaN          9.0  ...   \n",
              "2018-01-01 13:00:00             2.7            NaN          5.0  ...   \n",
              "\n",
              "nodes               6.0-85.0-5.0 6.0-85.0-6.0 6.0-87.0-1005.0 6.0-87.0-7.0  \\\n",
              "channels                    PM25         PM25            PM25         PM25   \n",
              "DateTime                                                                     \n",
              "2018-01-01 04:00:00          NaN          NaN             NaN          NaN   \n",
              "2018-01-01 05:00:00          NaN          NaN             NaN          NaN   \n",
              "2018-01-01 06:00:00          NaN          NaN             NaN          NaN   \n",
              "2018-01-01 07:00:00          NaN          NaN             NaN          NaN   \n",
              "2018-01-01 08:00:00        101.0         83.0            20.0         11.0   \n",
              "2018-01-01 09:00:00         81.0         88.0            18.0          7.0   \n",
              "2018-01-01 10:00:00         63.0        100.0            24.0          6.0   \n",
              "2018-01-01 11:00:00         58.0         74.0            25.0          7.0   \n",
              "2018-01-01 12:00:00         60.0         70.0            23.0         13.0   \n",
              "2018-01-01 13:00:00         55.0         66.0            18.0          6.0   \n",
              "\n",
              "nodes               6.0-9.0-1.0 6.0-95.0-4.0 6.0-99.0-5.0 6.0-99.0-6.0  \\\n",
              "channels                   PM25         PM25         PM25         PM25   \n",
              "DateTime                                                                 \n",
              "2018-01-01 04:00:00         NaN          NaN          NaN          NaN   \n",
              "2018-01-01 05:00:00         NaN          NaN          NaN          NaN   \n",
              "2018-01-01 06:00:00         NaN          NaN          NaN          NaN   \n",
              "2018-01-01 07:00:00         NaN          NaN          NaN          NaN   \n",
              "2018-01-01 08:00:00        15.0          NaN         43.0         60.0   \n",
              "2018-01-01 09:00:00        12.0          NaN         45.0         69.0   \n",
              "2018-01-01 10:00:00        14.0          NaN         36.0         64.0   \n",
              "2018-01-01 11:00:00        13.0          NaN         25.0         56.0   \n",
              "2018-01-01 12:00:00        14.0          NaN         21.0         52.0   \n",
              "2018-01-01 13:00:00        12.0          NaN         31.0         51.0   \n",
              "\n",
              "nodes               80.0-2.0-12.0 80.0-2.0-14.0  \n",
              "channels                     PM25          PM25  \n",
              "DateTime                                         \n",
              "2018-01-01 04:00:00           NaN           NaN  \n",
              "2018-01-01 05:00:00           NaN           NaN  \n",
              "2018-01-01 06:00:00           NaN           NaN  \n",
              "2018-01-01 07:00:00           NaN           NaN  \n",
              "2018-01-01 08:00:00         344.0         622.0  \n",
              "2018-01-01 09:00:00         292.0         744.0  \n",
              "2018-01-01 10:00:00         278.0         678.0  \n",
              "2018-01-01 11:00:00         296.0         688.0  \n",
              "2018-01-01 12:00:00         286.0         789.0  \n",
              "2018-01-01 13:00:00         297.0         809.0  \n",
              "\n",
              "[10 rows x 100 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.dataframe().head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN0pLP1IYVk8"
      },
      "source": [
        "### Get connectivity\n",
        "\n",
        "Besides the time series, to properly use graph-based models, we need to __connect__ nodes somehow.\n",
        "\n",
        "With the method `dataset.get_similarity()` we can retrieve nodes' similarities computed with different methods. The available similarity methods for a dataset can be found at `dataset.similarity_options`, while the default one is at `dataset.similarity_score`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NRZHPBhmYVk8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Default similarity: distance\n",
            "Available similarity options: {'distance'}\n",
            "\n",
            "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 1.0000000e+00 3.9095539e-01 1.7041542e-05 1.6665361e-05\n",
            "  1.1384949e-06 1.0476600e-06 3.9045709e-01 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 7.1743792e-01 1.0000000e+00 6.9196528e-04 6.8192312e-04\n",
            "  3.6181948e-06 3.3423953e-06 9.1603719e-02 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 9.7330508e-04 2.4218364e-06 1.0000000e+00 6.3372165e-01\n",
            "  4.0298249e-03 1.2675317e-02 2.2989086e-06 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 1.4520074e-03 4.0022201e-06 6.2646437e-01 1.0000000e+00\n",
            "  5.0620243e-02 1.3519681e-01 3.9826118e-06 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 1.4830440e-03 4.1195726e-06 8.9481241e-01 3.6143154e-01\n",
            "  1.0000000e+00 3.9011981e-02 4.1005305e-06 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 1.5491623e-06 0.0000000e+00 1.5777485e-02 6.7243795e-04\n",
            "  5.4904427e-02 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 5.2050585e-03 5.2495632e-02 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.2767867e-02]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00]]\n"
          ]
        }
      ],
      "source": [
        "print(f\"Default similarity: {dataset.similarity_score}\\n\"\n",
        "      f\"Available similarity options: {dataset.similarity_options}\\n\")\n",
        "\n",
        "sim = dataset.get_similarity(\"distance\")  # same as dataset.get_similarity()\n",
        "print(sim[:10, :10])  # just check first 10 nodes for readability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCcgblQAYVk8"
      },
      "source": [
        "With this method, we compute weight $w_t^{i,j}$ of the edge connecting $i$-th and $j$-th node as\n",
        "$$\n",
        "w^{i,j} = \\left\\{\\begin{array}{cl}\n",
        "     \\exp \\left(-\\frac{\\operatorname{dist}\\left(i, j\\right)^{2}}{\\gamma}\\right) & \\operatorname{dist}\\left(i, j\\right) \\leq \\delta  \\\\\n",
        "     0 & \\text{otherwise}\n",
        "\\end{array}\\right. ,\n",
        "$$\n",
        "where $\\operatorname{dist}\\left(i, j\\right)$ is the distance between $i$-th and $j$-th node, $\\gamma$ controls the width of the kernel and $\\delta$ is a threshold. Notice that in this case the similarity matrix is not symmetric, since the original preprocessed distance matrix is not symmetric too.\n",
        "\n",
        "So far so good, now we can build an adjacency matrix out ouf the computed similarity.\n",
        "\n",
        "The method `dataset.get_connectivity()`, wraps the `dataset.get_similarity()` module, provides useful preprocessing options, and, eventually, returns a sparse (weighted) adjacency matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "goTBHPNGYVk8"
      },
      "outputs": [],
      "source": [
        "adj = dataset.get_connectivity(threshold=0.1,\n",
        "                               include_self=False,\n",
        "                               normalize_axis=1,\n",
        "                               layout=\"edge_index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsPSdKmRYVk9"
      },
      "source": [
        "With this function call, under the hood we:\n",
        "\n",
        "1. compute the similarity matrix as before\n",
        "1. set to $0$ values below $0.1$ (`threshold=0.1`)\n",
        "1. remove self loops (`include_self=False`)\n",
        "1. normalize edge weights by the in degree of nodes (`normalize_axis=1`)\n",
        "1. request the sparse COO layout of PyG (`layout=\"edge_index\"`)\n",
        "\n",
        "The connectivity matrix with `edge_index` layout is provided in COO format, adopting the convention and notation used in PyTorch Geometric. The returned connectivity is a tuple (`edge_index`, `edge_weight`), where `edge_index` lists all edges as pairs of source-target nodes (dimensions `[2, E]`) and `edge_weight` (dimension `[E]`) stores the corresponding weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jD8S74swYVk9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 1515)\n",
            "[0.07963489 0.16290408 0.0310139  ... 0.04530123 0.03072186 0.11480146]\n"
          ]
        }
      ],
      "source": [
        "edge_index, edge_weight = adj\n",
        "\n",
        "print(edge_index.shape)\n",
        "print(edge_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaGwFbs4YVk9"
      },
      "source": [
        "The dense layout corresponds to the weighted adjacency matrix $A \\in \\mathbb{R}^{N \\times N}$. The module `tsl.ops.connectivity` contains useful operations for connectivities, including methods to change layout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gugmaNIpYVk9"
      },
      "outputs": [],
      "source": [
        "from tsl.ops.connectivity import edge_index_to_adj\n",
        "\n",
        "dense = edge_index_to_adj(edge_index, edge_weight)\n",
        "print(dense.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZB1SiBYYVk-"
      },
      "source": [
        "## Data processing\n",
        "---\n",
        "\n",
        "In this section, we will see how to transfer data from a dataset to an inference model (e.g., a spatiotemporal graph neural network).\n",
        "\n",
        "### The SpatioTemporalDataset\n",
        "\n",
        "The first class that comes in help is `tsl.data.SpatioTemporalDataset`. This class is a subclass of `torch.utils.data.Dataset` can be considered as wrapper of a `tsl` dataset providing the interface for further processing.\n",
        "\n",
        "In particular, a `SpatioTemporalDataset` object can be used to achieve the following:\n",
        "* perform the transformations required to feed the data to a model (e.g., casting to `torch.tensor`, handling different `shapes`)\n",
        "* handling temporal slicing and windowing for training (e.g., split data in $\\left( \\text{window}, \\text{horizon} \\right)$ samples)\n",
        "* defining the layout of inputs and targets (e.g., how node attributes and exogenous variables are arranged)\n",
        "* preprocess data before creating a batch\n",
        "\n",
        "Let's see how to go from a `Dataset` to a `SpatioTemporalDataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2VPMgQnYVk-"
      },
      "outputs": [],
      "source": [
        "from tsl.data import SpatioTemporalDataset\n",
        "\n",
        "torch_dataset = SpatioTemporalDataset(*dataset.numpy(return_idx=True),\n",
        "                                      connectivity=adj,\n",
        "                                      mask=dataset.mask,\n",
        "                                      horizon=12,\n",
        "                                      window=12)\n",
        "print(torch_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ap77CYPYVk-"
      },
      "source": [
        "As you can see, the number of samples is not the same as the number of steps we have in the dataset. Indeed, we divided the time series with a sliding window of 12 steps for the input (`window=12`), with a corresponding horizon of 12 steps (`horizon=12`). Thus, a sample spans for a total of $24$ steps. But let's look in details to the layout of a sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G7-8HMcYVk_"
      },
      "outputs": [],
      "source": [
        "sample = torch_dataset[0]\n",
        "print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXSGWvK5YVk_"
      },
      "source": [
        "A sample has 5 main attributes:\n",
        "\n",
        "* `sample.input` is a mapping of data to be forwarded as input to the model.\n",
        "* `sample.target` is a mapping of data to be forwarded as target for the loss function of the model.\n",
        "* `sample.mask` store the `mask`, if any. It is useful for computing the loss only on valid data.\n",
        "* `sample.transform` is a mapping containing as value a transformation function (e.g., scaling, detrending) and as key the name of the tensor to be transformed.\n",
        "* `sample.pattern` stores the pattern, i.e., a more informative shape representation, of each tensor in `sample`.\n",
        "\n",
        "Let's check more in details how each of these attributes is composed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tODoWS_YVk_"
      },
      "source": [
        "#### Input and Target\n",
        "\n",
        "A sample is a `tsl.data.Data` object which stores all that is needed to support inference.\n",
        "Both `input` and `target` are `tsl.data.DataView` of this storage.\n",
        "This means that they have the same methods, but contain different subsets keys.\n",
        "As a results, you cannot store two tensors using the key in `input` and `target`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbB9HvSoYVk_"
      },
      "outputs": [],
      "source": [
        "sample.input.to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdorD4uLYVk_"
      },
      "outputs": [],
      "source": [
        "sample.target.to_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNq8M-yaYVk_"
      },
      "source": [
        "#### Mask and Transform\n",
        "\n",
        "`mask` and `transform` are just symbolic links to the corresponding object inside the storage. They also expose properties `has_mask` and `has_transform`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAlbTjo7YVlA"
      },
      "outputs": [],
      "source": [
        "if sample.has_mask:\n",
        "    print(sample.mask)\n",
        "else:\n",
        "    print(\"Sample has no mask.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zW6tx42LYVlA"
      },
      "outputs": [],
      "source": [
        "if sample.has_transform:\n",
        "    print(sample.transform)\n",
        "else:\n",
        "    print(\"Sample has no transform functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR-LrjOwYVlA"
      },
      "source": [
        "#### Pattern\n",
        "\n",
        "The `pattern` mapping can be useful to glimpse on how data are arranged.\n",
        "The convention we use is the following:\n",
        "\n",
        "* \"b\" stands for \"batch size\"\n",
        "* \"c\" stands for \"number of channels\" (per node)\n",
        "* \"e\" stands for \"number edges\"\n",
        "* \"n\" stands for \"number of nodes\"\n",
        "* \"s\" stands for \"number of time steps\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KeKgewEYVlA"
      },
      "outputs": [],
      "source": [
        "sample.pattern"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j-pA8lCYVlA"
      },
      "source": [
        "### The SpatioTemporalDataModule\n",
        "\n",
        "Usually, before running an experiment there are two quite common preprocessing steps:\n",
        "\n",
        "* splitting the dataset into training/validation/test sets\n",
        "* data preprocessing (scaling/normalizing data, detrending)\n",
        "\n",
        "In `tsl`, these operations are carried out in the `tsl.data.SpatioTemporalDataModule`, which is based on `pytorch-lightning`'s data modules.\n",
        "\n",
        "Let's see an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aGnkoCgYVlA"
      },
      "outputs": [],
      "source": [
        "from tsl.data import SpatioTemporalDataModule\n",
        "from tsl.data.preprocessing import StandardScaler\n",
        "\n",
        "scalers = {'data': StandardScaler(axis=(0, 1))}\n",
        "\n",
        "splitter = dataset.get_splitter(val_len=0.1, test_len=0.2)\n",
        "\n",
        "dm = SpatioTemporalDataModule(\n",
        "    dataset=torch_dataset,\n",
        "    scalers=scalers,\n",
        "    splitter=splitter,\n",
        "    batch_size=64,\n",
        ")\n",
        "\n",
        "print(dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "229wC1LaYVlB"
      },
      "source": [
        " Eventually one could extend the base datamodule to add further processing in case it is needed.\n",
        "\n",
        "At this point, the `DataModule` object has not actually performed any processing yet (lazy approach).\n",
        "\n",
        "We can execute the preprocessing routines by calling `setup` method.\n",
        "\n",
        "Note that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMpX1zbfYVlB"
      },
      "outputs": [],
      "source": [
        "dm.setup()\n",
        "print(dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXQy8qMDYVlB"
      },
      "source": [
        "After `setup` has been called, the datamodule carries the following operations:\n",
        "\n",
        "1. Carries out the dataset splitting into training/validation/test sets according to the `splitter` argument.\n",
        "1. Fits all the `Scalers` on the training data in `dataset` corresponding to the scalers' keys.\n",
        "\n",
        "#### Scalers\n",
        "\n",
        "The `tsl.data.preprocessing` package offers several of the most common data normalization techniques under the `tsl.data.preprocessing.Scaler` interface.\n",
        "They adopt an API similar to `scikit-learn`'s scalers, with `fit`/`transform`/`fit_transform`/`inverse_transform` methods. Check the documentation for more details about this.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d60HdqXCYVlB"
      },
      "source": [
        "## Building a Model\n",
        "---\n",
        "\n",
        "In this section, we will see how to build a very simple Graph Neural Network for Spatiotemporal data.\n",
        "All the neural network code inside `tsl` is under the `tsl.nn` module.\n",
        "\n",
        "\n",
        "### The NN module\n",
        "\n",
        "The `tsl.nn` module is organized as follows:\n",
        "\n",
        "```\n",
        "tsl\n",
        "└── nn\n",
        "    ├── base\n",
        "    ├── blocks\n",
        "    ├── layers\n",
        "    ├── models\n",
        "    ├── metrics\n",
        "    ├── ops\n",
        "    └── utils\n",
        "```\n",
        "\n",
        "The 3 most important submodules in it are `layers`, `blocks`, and `models`, ordered by increasing level of abstraction.\n",
        "\n",
        "#### Layers\n",
        "\n",
        "A _layer_ is a basic building block for our neural networks. In simple words, a layer takes an input, performs one (or few) operations, and return a transformation of the input. Examples of layers are `DiffConv`, which implements [diffusion convolution](https://arxiv.org/abs/1707.01926), or `LayerNorm`.\n",
        "\n",
        "#### Blocks\n",
        "\n",
        "_blocks_ perform more complex transformations or combine several operations. We divide blocks into _encoders_, if they provide a representation of the input in a new space, and _decoders_, if they produce a meaningful output from a representation.\n",
        "\n",
        "#### Models\n",
        "\n",
        "We wrap a series of operations, represented by blocks and/or layers, in a _model_. A model is meant to takes as input a batch `SpatioTemporalDataset`'s items and return the desired output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQiMvBjGYVlC"
      },
      "source": [
        "Let's create a very simple model with a RNN encoder and a nonlinear GCN readout.\n",
        "To do so, we import `RNN` from the encoders and `GCNDecoder` from the decoders in the `tsl.nn.blocks` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORL_KKbuYVlC"
      },
      "outputs": [],
      "source": [
        "from tsl.nn.blocks.encoders import RNN\n",
        "from tsl.nn.blocks.decoders import GCNDecoder\n",
        "\n",
        "\n",
        "class TimeThenSpaceModel(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 hidden_size,\n",
        "                 rnn_layers,\n",
        "                 gcn_layers,\n",
        "                 horizon):\n",
        "        super(TimeThenSpaceModel, self).__init__()\n",
        "\n",
        "        self.input_encoder = torch.nn.Linear(input_size, hidden_size)\n",
        "\n",
        "        self.encoder = RNN(input_size=hidden_size,\n",
        "                           hidden_size=hidden_size,\n",
        "                           n_layers=rnn_layers)\n",
        "\n",
        "        self.decoder = GCNDecoder(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            output_size=input_size,\n",
        "            horizon=horizon,\n",
        "            n_layers=gcn_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight):\n",
        "        # x: [batches steps nodes channels]\n",
        "        x = self.input_encoder(x)\n",
        "\n",
        "        x = self.encoder(x, return_last_state=True)\n",
        "\n",
        "        return self.decoder(x, edge_index, edge_weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fu_1-ojYVlC"
      },
      "source": [
        "Fine, we have a model and we have data, now let's train it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3uABycjYVlC"
      },
      "source": [
        "## Setting up training\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxvEqv95YVlC"
      },
      "source": [
        "### The Predictor\n",
        "\n",
        "In `tsl`, inference engines are implemented as a [`LightningModule`](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.LightningModule.html#pytorch_lightning.core.LightningModule). `tsl.predictors.Predictor` is a base class that can be extended to build more complex forecasting approaches.\n",
        "These modules are meant to wrap deep models in order to ease training and inference phases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GULyga_lYVlD"
      },
      "outputs": [],
      "source": [
        "from tsl.nn.metrics.metrics import MaskedMAE, MaskedMAPE\n",
        "from tsl.predictors import Predictor\n",
        "\n",
        "loss_fn = MaskedMAE(compute_on_step=True)\n",
        "\n",
        "metrics = {'mae': MaskedMAE(compute_on_step=False),\n",
        "           'mape': MaskedMAPE(compute_on_step=False),\n",
        "           'mae_at_15': MaskedMAE(compute_on_step=False, at=2),  # `2` indicated the third time step,\n",
        "                                                                 # which correspond to 15 minutes ahead\n",
        "           'mae_at_30': MaskedMAE(compute_on_step=False, at=5),\n",
        "           'mae_at_60': MaskedMAE(compute_on_step=False, at=11), }\n",
        "\n",
        "model_kwargs = {\n",
        "    'input_size': dm.n_channels,  # 1 channel\n",
        "    'horizon': dm.horizon,  # 12, the number of steps ahead to forecast\n",
        "    'hidden_size': 32,\n",
        "    'rnn_layers': 1,\n",
        "    'gcn_layers': 2\n",
        "}\n",
        "\n",
        "# setup predictor\n",
        "predictor = Predictor(\n",
        "    model_class=TimeThenSpaceModel,\n",
        "    model_kwargs=model_kwargs,\n",
        "    optim_class=torch.optim.Adam,\n",
        "    optim_kwargs={'lr': 0.001},\n",
        "    loss_fn=loss_fn,\n",
        "    metrics=metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-34Ntg3lYVlD"
      },
      "source": [
        "Now let's finalize the last details. We make use of [TensorBoard](https://www.tensorflow.org/tensorboard/) to log and visualize metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3zdVgNRYVlD"
      },
      "outputs": [],
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "logger = TensorBoardLogger(save_dir=\"logs\", name=\"tsl_intro\", version=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4IU2vFKYVlD"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1b57xoTYVlD"
      },
      "source": [
        "We let `pytorch_lightning.Trainer` handle the dirty work for us. We can directly pass the datamodule to the trainer for fitting.\n",
        "\n",
        "If this is the case, the trainer will call the `setup` method, and then load train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSJLVCaFYVlD"
      },
      "outputs": [],
      "source": [
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath='logs',\n",
        "    save_top_k=1,\n",
        "    monitor='val_mae',\n",
        "    mode='min',\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(max_epochs=100,\n",
        "                     logger=logger,\n",
        "                     gpus=1 if torch.cuda.is_available() else None,\n",
        "                     limit_train_batches=100,\n",
        "                     callbacks=[checkpoint_callback])\n",
        "\n",
        "trainer.fit(predictor, datamodule=dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bAHFLAEYVlE"
      },
      "source": [
        "## Testing\n",
        "---\n",
        "\n",
        "\n",
        "Now let's see how the trained model behaves on new unseen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aV-v6EfCYVlE"
      },
      "outputs": [],
      "source": [
        "predictor.load_model(checkpoint_callback.best_model_path)\n",
        "predictor.freeze()\n",
        "\n",
        "performance = trainer.test(predictor, datamodule=dm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRd_FMpyYVlE"
      },
      "source": [
        "Cool! We succeeded in creating first a simple, yet effective, SpatioTemporal model!\n",
        "\n",
        "We are now __tsl ninjas__. We learned how to:\n",
        "\n",
        "* Load benchmark datasets\n",
        "* Organize data for processing\n",
        "* Preprocess the data\n",
        "* Build a Spatiotemporal GNN\n",
        "* Train and evaluate the model\n",
        "\n",
        "We hope you enjoyed this introduction to `tsl`, do not hesitate to contact us if you have any question or problem while using it.\n",
        "\n",
        "The tsl team.\n",
        "\n",
        "🧡"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "a_gentle_introduction_to_tsl.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
