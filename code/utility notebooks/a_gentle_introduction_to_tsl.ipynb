{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/TorchSpatiotemporal/tsl/blob/main/examples/notebooks/a_gentle_introduction_to_tsl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xxE1lI-YVk2"
   },
   "source": [
    "# A Gentle Introduction to tsl\n",
    "---\n",
    "\n",
    "This a tutorial notebook about __tsl (Torch Spatiotemporal)__, a Python library built upon the PyTorch ecosystem\n",
    "and tailored for spatiotemporal data processing.\n",
    "\n",
    "In this notebook we are going to see what are the necessary steps from data loading to model training.\n",
    "\n",
    "## Installation\n",
    "---\n",
    "\n",
    "Let's start by the installation. If you run the notebook in colab, you can install tsl with these commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xJwaWoSrYVk3"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/TorchSpatiotemporal/tsl.git\n",
    "!pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install torch-scatter torch-sparse torch-geometric -f https://data.pyg.org/whl/torch-1.10.1+cu113.html\n",
    "!pip install ./tsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "ZxoqCutTYVk4"
   },
   "source": [
    "In particular, the second command is installing `torch-geometric` dependencies for the specific environment you have on colab with GPU runtime. Please refer to [PyG installation guidelines](https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html) for installation in other environments.\n",
    "\n",
    "We recommend to install tsl from GitHub repository at the moment, to be sure you are up-to-date with latest version.\n",
    "\n",
    "Let's check if everything is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hLAxpbejYVk4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsl version  : 0.1.0\n",
      "torch version: 1.11.0+cu102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/tqdm-4.64.0-py3.9.egg/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tsl\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "tsl.logger.disabled = True\n",
    "\n",
    "print(f\"tsl version  : {tsl.__version__}\")\n",
    "print(f\"torch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "D_bK40BaYVk5"
   },
   "source": [
    "## Usage\n",
    "---\n",
    "\n",
    "tsl is more than a collection of layers. We can classify the library modules into:\n",
    "\n",
    "* __Data loading modules__\n",
    "    Manage how to store, preprocess and visualize spatio-temporal data\n",
    "* __Inference modules__\n",
    "    Methods and models exploiting the data to make inferences\n",
    "\n",
    "We will go deeper on them in next sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wy4OORcYVk5"
   },
   "source": [
    "## Data loading\n",
    "---\n",
    "\n",
    "`tsl` comes with several datasets used in spatiotemporal processing literature. You can find them inside the submodule `tsl.datasets`.\n",
    "\n",
    "### Loading the dataset\n",
    "\n",
    "As an example, we start by using the [MetrLA](https://paperswithcode.com/sota/traffic-prediction-on-metr-la) dataset, a common benchmark for traffic forecasting. The dataset contains traffic readings collected from 207 loop detectors on highways in Los Angeles County, aggregated in 5 minute intervals for 4 months between March 2012 to June 2012. Loading the dataset is as simple as that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BsPkG4uMYVk5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/torch-1.11.0-py3.9-linux-x86_64.egg/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "from tsl.datasets import AirQuality as AQ\n",
    "\n",
    "dataset = AQ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67IyIupLYVk6"
   },
   "source": [
    "We can see that data are organized a 3-dimensional array, with:\n",
    "\n",
    "* 34.272 temporal steps (1 each 5 minute for 4 months)\n",
    "* 207 nodes (the loop detectors)\n",
    "* 1 channels (detected speed)\n",
    "\n",
    "Nice! Other than storing the data of interest, the dataset comes with useful tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "L74iikTiYVk6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling period: <Hour>\n",
      "Has missing values: True\n",
      "Percentage of missing values: 25.67%\n",
      "Has dataset exogenous variables: False\n",
      "Relevant attributes: dist\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sampling period: {dataset.freq}\\n\"\n",
    "      f\"Has missing values: {dataset.has_mask}\\n\"\n",
    "      f\"Percentage of missing values: {(1 - dataset.mask.mean()) * 100:.2f}%\\n\"\n",
    "      f\"Has dataset exogenous variables: {dataset.has_exogenous}\\n\"\n",
    "      f\"Relevant attributes: {', '.join(dataset.attributes.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TC8LfuK4YVk6"
   },
   "source": [
    "Let's look at the output. We know that the dataset has missing entries, with `dataset.mask` being a binary indicator associated with each timestep, node and channel (with ones indicating valid values).\n",
    "\n",
    "Also, the dataset has no exogenous variables, i.e., there are no time-varying features paired with the main signal.\n",
    "Instead it has a useful attribute: the distance matrix. We call *attributes*, features that are static.\n",
    "\n",
    "You can access exogenous variables and attributes by `dataset.name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_YgmDUtWYVk7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.           10.01553231   19.62147943 ... 1903.71716932\n",
      "  1796.30609352 1795.96589939]\n",
      " [  10.01553231    0.           10.11719073 ... 1895.15226463\n",
      "  1787.72195802 1787.39244677]\n",
      " [  19.62147943   10.11719073    0.         ... 1885.08052065\n",
      "  1777.64679953 1777.31922415]\n",
      " ...\n",
      " [1903.71716932 1895.15226463 1885.08052065 ...    0.\n",
      "   107.63326768  107.79738345]\n",
      " [1796.30609352 1787.72195802 1777.64679953 ...  107.63326768\n",
      "     0.            3.6701503 ]\n",
      " [1795.96589939 1787.39244677 1777.31922415 ...  107.79738345\n",
      "     3.6701503     0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1uMQREKYVk7"
   },
   "source": [
    "This matrix stores the pairwise distance between sensors, with `inf` denoting two non-neighboring sensors.\n",
    "\n",
    "Let's now check how the speed readings look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hxqyccSSYVk7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>nodes</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>1004</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>1008</th>\n",
       "      <th>1009</th>\n",
       "      <th>1010</th>\n",
       "      <th>...</th>\n",
       "      <th>311002</th>\n",
       "      <th>311003</th>\n",
       "      <th>311004</th>\n",
       "      <th>311005</th>\n",
       "      <th>371001</th>\n",
       "      <th>371002</th>\n",
       "      <th>371003</th>\n",
       "      <th>371004</th>\n",
       "      <th>372001</th>\n",
       "      <th>372002</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>channels</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-05-01 00:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>84.112572</td>\n",
       "      <td>71.215103</td>\n",
       "      <td>45.315453</td>\n",
       "      <td>39.634724</td>\n",
       "      <td>45.188107</td>\n",
       "      <td>57.007835</td>\n",
       "      <td>63.501968</td>\n",
       "      <td>61.792046</td>\n",
       "      <td>75.698006</td>\n",
       "      <td>77.257301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01 01:00:00</th>\n",
       "      <td>124.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>82.447189</td>\n",
       "      <td>71.837502</td>\n",
       "      <td>45.932846</td>\n",
       "      <td>42.260418</td>\n",
       "      <td>46.544907</td>\n",
       "      <td>54.195034</td>\n",
       "      <td>57.988342</td>\n",
       "      <td>59.111382</td>\n",
       "      <td>70.341698</td>\n",
       "      <td>72.044922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01 02:00:00</th>\n",
       "      <td>127.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.896912</td>\n",
       "      <td>72.029999</td>\n",
       "      <td>46.272568</td>\n",
       "      <td>41.574722</td>\n",
       "      <td>46.479549</td>\n",
       "      <td>54.222298</td>\n",
       "      <td>57.437904</td>\n",
       "      <td>58.276581</td>\n",
       "      <td>69.585495</td>\n",
       "      <td>71.153893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01 03:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.969444</td>\n",
       "      <td>73.082085</td>\n",
       "      <td>45.956978</td>\n",
       "      <td>42.710938</td>\n",
       "      <td>46.156586</td>\n",
       "      <td>50.423290</td>\n",
       "      <td>53.261192</td>\n",
       "      <td>55.609005</td>\n",
       "      <td>65.937805</td>\n",
       "      <td>68.518791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01 04:00:00</th>\n",
       "      <td>119.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>75.767670</td>\n",
       "      <td>70.022392</td>\n",
       "      <td>43.757290</td>\n",
       "      <td>38.416008</td>\n",
       "      <td>46.463467</td>\n",
       "      <td>48.486259</td>\n",
       "      <td>52.067562</td>\n",
       "      <td>53.363712</td>\n",
       "      <td>63.745544</td>\n",
       "      <td>65.624329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01 05:00:00</th>\n",
       "      <td>127.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.315071</td>\n",
       "      <td>68.437187</td>\n",
       "      <td>45.163715</td>\n",
       "      <td>38.913403</td>\n",
       "      <td>46.257393</td>\n",
       "      <td>45.349560</td>\n",
       "      <td>48.231865</td>\n",
       "      <td>51.182884</td>\n",
       "      <td>59.617985</td>\n",
       "      <td>59.522064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01 06:00:00</th>\n",
       "      <td>124.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.613335</td>\n",
       "      <td>69.719688</td>\n",
       "      <td>45.270348</td>\n",
       "      <td>37.547012</td>\n",
       "      <td>43.457443</td>\n",
       "      <td>44.056183</td>\n",
       "      <td>49.775440</td>\n",
       "      <td>51.103504</td>\n",
       "      <td>61.608974</td>\n",
       "      <td>62.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01 07:00:00</th>\n",
       "      <td>120.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73.320137</td>\n",
       "      <td>67.786980</td>\n",
       "      <td>44.284027</td>\n",
       "      <td>39.611458</td>\n",
       "      <td>42.539032</td>\n",
       "      <td>43.371082</td>\n",
       "      <td>49.522362</td>\n",
       "      <td>50.645584</td>\n",
       "      <td>59.658863</td>\n",
       "      <td>60.610733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01 08:00:00</th>\n",
       "      <td>123.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.309616</td>\n",
       "      <td>68.352432</td>\n",
       "      <td>46.280727</td>\n",
       "      <td>38.855209</td>\n",
       "      <td>42.173878</td>\n",
       "      <td>44.351986</td>\n",
       "      <td>51.423634</td>\n",
       "      <td>51.125401</td>\n",
       "      <td>59.675674</td>\n",
       "      <td>61.104847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-05-01 09:00:00</th>\n",
       "      <td>147.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>...</td>\n",
       "      <td>78.576218</td>\n",
       "      <td>71.911110</td>\n",
       "      <td>45.597050</td>\n",
       "      <td>36.502083</td>\n",
       "      <td>44.398849</td>\n",
       "      <td>46.701988</td>\n",
       "      <td>55.168285</td>\n",
       "      <td>52.946709</td>\n",
       "      <td>64.275314</td>\n",
       "      <td>63.696835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "nodes               1001   1002   1003   1004   1005   1006   1007   1008    \\\n",
       "channels                 0      0      0      0      0      0      0      0   \n",
       "time                                                                          \n",
       "2014-05-01 00:00:00  138.0   89.0  105.0   98.0  109.0   87.0   88.0   91.0   \n",
       "2014-05-01 01:00:00  124.0   85.0  121.0  107.0  101.0   99.0  105.0  102.0   \n",
       "2014-05-01 02:00:00  127.0   88.0  130.0  115.0  102.0  109.0  114.0  108.0   \n",
       "2014-05-01 03:00:00  129.0  100.0  137.0  123.0  108.0  118.0  118.0  109.0   \n",
       "2014-05-01 04:00:00  119.0  109.0  144.0  129.0  115.0  124.0  130.0  116.0   \n",
       "2014-05-01 05:00:00  127.0  120.0  142.0  138.0  123.0  134.0  140.0  127.0   \n",
       "2014-05-01 06:00:00  124.0  127.0  112.0  146.0  142.0  142.0  142.0  134.0   \n",
       "2014-05-01 07:00:00  120.0  114.0  108.0  144.0  146.0  140.0  150.0  136.0   \n",
       "2014-05-01 08:00:00  123.0  121.0  141.0  151.0  130.0  130.0  139.0  146.0   \n",
       "2014-05-01 09:00:00  147.0  133.0  148.0  168.0  158.0  139.0  158.0  155.0   \n",
       "\n",
       "nodes               1009   1010    ...     311002     311003     311004  \\\n",
       "channels                 0      0  ...          0          0          0   \n",
       "time                               ...                                    \n",
       "2014-05-01 00:00:00   87.0   87.0  ...  84.112572  71.215103  45.315453   \n",
       "2014-05-01 01:00:00  103.0   94.0  ...  82.447189  71.837502  45.932846   \n",
       "2014-05-01 02:00:00  112.0  109.0  ...  78.896912  72.029999  46.272568   \n",
       "2014-05-01 03:00:00  117.0  111.0  ...  78.969444  73.082085  45.956978   \n",
       "2014-05-01 04:00:00  124.0  114.0  ...  75.767670  70.022392  43.757290   \n",
       "2014-05-01 05:00:00  132.0  121.0  ...  73.315071  68.437187  45.163715   \n",
       "2014-05-01 06:00:00  138.0  113.0  ...  74.613335  69.719688  45.270348   \n",
       "2014-05-01 07:00:00  142.0  135.0  ...  73.320137  67.786980  44.284027   \n",
       "2014-05-01 08:00:00  156.0  148.0  ...  74.309616  68.352432  46.280727   \n",
       "2014-05-01 09:00:00  168.0  163.0  ...  78.576218  71.911110  45.597050   \n",
       "\n",
       "nodes                   311005     371001     371002     371003     371004  \\\n",
       "channels                     0          0          0          0          0   \n",
       "time                                                                         \n",
       "2014-05-01 00:00:00  39.634724  45.188107  57.007835  63.501968  61.792046   \n",
       "2014-05-01 01:00:00  42.260418  46.544907  54.195034  57.988342  59.111382   \n",
       "2014-05-01 02:00:00  41.574722  46.479549  54.222298  57.437904  58.276581   \n",
       "2014-05-01 03:00:00  42.710938  46.156586  50.423290  53.261192  55.609005   \n",
       "2014-05-01 04:00:00  38.416008  46.463467  48.486259  52.067562  53.363712   \n",
       "2014-05-01 05:00:00  38.913403  46.257393  45.349560  48.231865  51.182884   \n",
       "2014-05-01 06:00:00  37.547012  43.457443  44.056183  49.775440  51.103504   \n",
       "2014-05-01 07:00:00  39.611458  42.539032  43.371082  49.522362  50.645584   \n",
       "2014-05-01 08:00:00  38.855209  42.173878  44.351986  51.423634  51.125401   \n",
       "2014-05-01 09:00:00  36.502083  44.398849  46.701988  55.168285  52.946709   \n",
       "\n",
       "nodes                   372001     372002  \n",
       "channels                     0          0  \n",
       "time                                       \n",
       "2014-05-01 00:00:00  75.698006  77.257301  \n",
       "2014-05-01 01:00:00  70.341698  72.044922  \n",
       "2014-05-01 02:00:00  69.585495  71.153893  \n",
       "2014-05-01 03:00:00  65.937805  68.518791  \n",
       "2014-05-01 04:00:00  63.745544  65.624329  \n",
       "2014-05-01 05:00:00  59.617985  59.522064  \n",
       "2014-05-01 06:00:00  61.608974  62.009888  \n",
       "2014-05-01 07:00:00  59.658863  60.610733  \n",
       "2014-05-01 08:00:00  59.675674  61.104847  \n",
       "2014-05-01 09:00:00  64.275314  63.696835  \n",
       "\n",
       "[10 rows x 437 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataframe().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN0pLP1IYVk8"
   },
   "source": [
    "### Get connectivity\n",
    "\n",
    "Besides the time series, to properly use graph-based models, we need to __connect__ nodes somehow.\n",
    "\n",
    "With the method `dataset.get_similarity()` we can retrieve nodes' similarities computed with different methods. The available similarity methods for a dataset can be found at `dataset.similarity_options`, while the default one is at `dataset.similarity_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NRZHPBhmYVk8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default similarity: distance\n",
      "Available similarity options: {'distance'}\n",
      "\n",
      "[[1.         0.86853818 0.58219195 0.26736404 0.12036526 0.72780463\n",
      "  0.48905501 0.52840458 0.32986479 0.27389788]\n",
      " [0.86853818 1.         0.86604411 0.53188295 0.29106698 0.92904057\n",
      "  0.68073739 0.77580368 0.60992591 0.52348866]\n",
      " [0.58219195 0.86604411 1.         0.84114444 0.58530849 0.81783541\n",
      "  0.58075869 0.73745742 0.73309012 0.62165892]\n",
      " [0.26736404 0.53188295 0.84114444 1.         0.90157624 0.52029781\n",
      "  0.36513726 0.51747668 0.66768938 0.56361474]\n",
      " [0.12036526 0.29106698 0.58530849 0.90157624 1.         0.27983269\n",
      "  0.18380225 0.2894282  0.45086383 0.37104449]\n",
      " [0.72780463 0.92904057 0.81783541 0.52029781 0.27983269 1.\n",
      "  0.88357588 0.9437749  0.77927832 0.7185383 ]\n",
      " [0.48905501 0.68073739 0.58075869 0.36513726 0.18380225 0.88357588\n",
      "  1.         0.96315672 0.81181861 0.82296991]\n",
      " [0.52840458 0.77580368 0.73745742 0.51747668 0.2894282  0.9437749\n",
      "  0.96315672 1.         0.90479142 0.88158209]\n",
      " [0.32986479 0.60992591 0.73309012 0.66768938 0.45086383 0.77927832\n",
      "  0.81181861 0.90479142 1.         0.98201527]\n",
      " [0.27389788 0.52348866 0.62165892 0.56361474 0.37104449 0.7185383\n",
      "  0.82296991 0.88158209 0.98201527 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Default similarity: {dataset.similarity_score}\\n\"\n",
    "      f\"Available similarity options: {dataset.similarity_options}\\n\")\n",
    "\n",
    "sim = dataset.get_similarity(\"distance\")  # same as dataset.get_similarity()\n",
    "print(sim[:10, :10])  # just check first 10 nodes for readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCcgblQAYVk8"
   },
   "source": [
    "With this method, we compute weight $w_t^{i,j}$ of the edge connecting $i$-th and $j$-th node as\n",
    "$$\n",
    "w^{i,j} = \\left\\{\\begin{array}{cl}\n",
    "     \\exp \\left(-\\frac{\\operatorname{dist}\\left(i, j\\right)^{2}}{\\gamma}\\right) & \\operatorname{dist}\\left(i, j\\right) \\leq \\delta  \\\\\n",
    "     0 & \\text{otherwise}\n",
    "\\end{array}\\right. ,\n",
    "$$\n",
    "where $\\operatorname{dist}\\left(i, j\\right)$ is the distance between $i$-th and $j$-th node, $\\gamma$ controls the width of the kernel and $\\delta$ is a threshold. Notice that in this case the similarity matrix is not symmetric, since the original preprocessed distance matrix is not symmetric too.\n",
    "\n",
    "So far so good, now we can build an adjacency matrix out ouf the computed similarity.\n",
    "\n",
    "The method `dataset.get_connectivity()`, wraps the `dataset.get_similarity()` module, provides useful preprocessing options, and, eventually, returns a sparse (weighted) adjacency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "goTBHPNGYVk8"
   },
   "outputs": [],
   "source": [
    "adj = dataset.get_connectivity(threshold=0.1,\n",
    "                               include_self=False,\n",
    "                               normalize_axis=1,\n",
    "                               layout=\"edge_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsPSdKmRYVk9"
   },
   "source": [
    "With this function call, under the hood we:\n",
    "\n",
    "1. compute the similarity matrix as before\n",
    "1. set to $0$ values below $0.1$ (`threshold=0.1`)\n",
    "1. remove self loops (`include_self=False`)\n",
    "1. normalize edge weights by the in degree of nodes (`normalize_axis=1`)\n",
    "1. request the sparse COO layout of PyG (`layout=\"edge_index\"`)\n",
    "\n",
    "The connectivity matrix with `edge_index` layout is provided in COO format, adopting the convention and notation used in PyTorch Geometric. The returned connectivity is a tuple (`edge_index`, `edge_weight`), where `edge_index` lists all edges as pairs of source-target nodes (dimensions `[2, E]`) and `edge_weight` (dimension `[E]`) stores the corresponding weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jD8S74swYVk9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5398)\n",
      "[0.06717467 0.04276256 0.0225386  ... 0.34616419 0.99999995 0.99999995]\n"
     ]
    }
   ],
   "source": [
    "edge_index, edge_weight = adj\n",
    "\n",
    "print(edge_index.shape)\n",
    "print(edge_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KaGwFbs4YVk9"
   },
   "source": [
    "The dense layout corresponds to the weighted adjacency matrix $A \\in \\mathbb{R}^{N \\times N}$. The module `tsl.ops.connectivity` contains useful operations for connectivities, including methods to change layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gugmaNIpYVk9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(437, 437)\n"
     ]
    }
   ],
   "source": [
    "from tsl.ops.connectivity import edge_index_to_adj\n",
    "\n",
    "dense = edge_index_to_adj(edge_index, edge_weight)\n",
    "print(dense.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ZB1SiBYYVk-"
   },
   "source": [
    "## Data processing\n",
    "---\n",
    "\n",
    "In this section, we will see how to transfer data from a dataset to an inference model (e.g., a spatiotemporal graph neural network).\n",
    "\n",
    "### The SpatioTemporalDataset\n",
    "\n",
    "The first class that comes in help is `tsl.data.SpatioTemporalDataset`. This class is a subclass of `torch.utils.data.Dataset` can be considered as wrapper of a `tsl` dataset providing the interface for further processing.\n",
    "\n",
    "In particular, a `SpatioTemporalDataset` object can be used to achieve the following:\n",
    "* perform the transformations required to feed the data to a model (e.g., casting to `torch.tensor`, handling different `shapes`)\n",
    "* handling temporal slicing and windowing for training (e.g., split data in $\\left( \\text{window}, \\text{horizon} \\right)$ samples)\n",
    "* defining the layout of inputs and targets (e.g., how node attributes and exogenous variables are arranged)\n",
    "* preprocess data before creating a batch\n",
    "\n",
    "Let's see how to go from a `Dataset` to a `SpatioTemporalDataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "s2VPMgQnYVk-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataset(n_samples=8737, n_nodes=437, n_channels=1)\n"
     ]
    }
   ],
   "source": [
    "from tsl.data import SpatioTemporalDataset\n",
    "\n",
    "torch_dataset = SpatioTemporalDataset(*dataset.numpy(return_idx=True),\n",
    "                                      connectivity=adj,\n",
    "                                      mask=dataset.mask,\n",
    "                                      horizon=12,\n",
    "                                      window=12)\n",
    "print(torch_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Ap77CYPYVk-"
   },
   "source": [
    "As you can see, the number of samples is not the same as the number of steps we have in the dataset. Indeed, we divided the time series with a sliding window of 12 steps for the input (`window=12`), with a corresponding horizon of 12 steps (`horizon=12`). Thus, a sample spans for a total of $24$ steps. But let's look in details to the layout of a sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_G7-8HMcYVk_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(input:{x=[12, 437, 1], edge_index=[2, 5398], edge_weight=[5398]}, target:{y=[12, 437, 1]}, has_mask=True)\n"
     ]
    }
   ],
   "source": [
    "sample = torch_dataset[0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXSGWvK5YVk_"
   },
   "source": [
    "A sample has 5 main attributes:\n",
    "\n",
    "* `sample.input` is a mapping of data to be forwarded as input to the model.\n",
    "* `sample.target` is a mapping of data to be forwarded as target for the loss function of the model.\n",
    "* `sample.mask` store the `mask`, if any. It is useful for computing the loss only on valid data.\n",
    "* `sample.transform` is a mapping containing as value a transformation function (e.g., scaling, detrending) and as key the name of the tensor to be transformed.\n",
    "* `sample.pattern` stores the pattern, i.e., a more informative shape representation, of each tensor in `sample`.\n",
    "\n",
    "Let's check more in details how each of these attributes is composed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tODoWS_YVk_"
   },
   "source": [
    "#### Input and Target\n",
    "\n",
    "A sample is a `tsl.data.Data` object which stores all that is needed to support inference.\n",
    "Both `input` and `target` are `tsl.data.DataView` of this storage.\n",
    "This means that they have the same methods, but contain different subsets keys.\n",
    "As a results, you cannot store two tensors using the key in `input` and `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TbB9HvSoYVk_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[[138.0000],\n",
       "          [ 89.0000],\n",
       "          [105.0000],\n",
       "          ...,\n",
       "          [ 61.7920],\n",
       "          [ 75.6980],\n",
       "          [ 77.2573]],\n",
       " \n",
       "         [[124.0000],\n",
       "          [ 85.0000],\n",
       "          [121.0000],\n",
       "          ...,\n",
       "          [ 59.1114],\n",
       "          [ 70.3417],\n",
       "          [ 72.0449]],\n",
       " \n",
       "         [[127.0000],\n",
       "          [ 88.0000],\n",
       "          [130.0000],\n",
       "          ...,\n",
       "          [ 58.2766],\n",
       "          [ 69.5855],\n",
       "          [ 71.1539]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[147.0000],\n",
       "          [133.0000],\n",
       "          [148.0000],\n",
       "          ...,\n",
       "          [ 52.9467],\n",
       "          [ 64.2753],\n",
       "          [ 63.6968]],\n",
       " \n",
       "         [[188.0000],\n",
       "          [ 29.0000],\n",
       "          [167.0000],\n",
       "          ...,\n",
       "          [ 53.2139],\n",
       "          [ 63.2178],\n",
       "          [ 63.1341]],\n",
       " \n",
       "         [[212.0000],\n",
       "          [ 33.3333],\n",
       "          [178.0000],\n",
       "          ...,\n",
       "          [ 55.3667],\n",
       "          [ 64.9315],\n",
       "          [ 65.9394]]]),\n",
       " 'edge_index': tensor([[  0,   0,   0,  ..., 434, 435, 436],\n",
       "         [  1,   2,   3,  ..., 433, 436, 435]]),\n",
       " 'edge_weight': tensor([0.0672, 0.0428, 0.0225,  ..., 0.3462, 1.0000, 1.0000])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.input.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "HdorD4uLYVk_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y': tensor([[[229.0000],\n",
       "          [111.0000],\n",
       "          [179.0000],\n",
       "          ...,\n",
       "          [ 55.8811],\n",
       "          [ 68.1196],\n",
       "          [ 66.7615]],\n",
       " \n",
       "         [[240.0000],\n",
       "          [172.0000],\n",
       "          [184.0000],\n",
       "          ...,\n",
       "          [ 53.8635],\n",
       "          [ 67.5794],\n",
       "          [ 67.3180]],\n",
       " \n",
       "         [[240.0000],\n",
       "          [173.0000],\n",
       "          [188.0000],\n",
       "          ...,\n",
       "          [ 52.7024],\n",
       "          [ 63.6870],\n",
       "          [ 63.7933]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[119.0000],\n",
       "          [ 51.0000],\n",
       "          [ 50.0000],\n",
       "          ...,\n",
       "          [ 61.6110],\n",
       "          [ 73.4010],\n",
       "          [ 70.2052]],\n",
       " \n",
       "         [[ 48.0000],\n",
       "          [ 33.0000],\n",
       "          [ 36.0000],\n",
       "          ...,\n",
       "          [ 67.3310],\n",
       "          [ 78.3555],\n",
       "          [ 77.4719]],\n",
       " \n",
       "         [[ 37.0000],\n",
       "          [ 31.0000],\n",
       "          [ 34.0000],\n",
       "          ...,\n",
       "          [ 63.4985],\n",
       "          [ 76.7035],\n",
       "          [ 82.3329]]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.target.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNq8M-yaYVk_"
   },
   "source": [
    "#### Mask and Transform\n",
    "\n",
    "`mask` and `transform` are just symbolic links to the corresponding object inside the storage. They also expose properties `has_mask` and `has_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rAlbTjo7YVlA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         ...,\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "if sample.has_mask:\n",
    "    print(sample.mask)\n",
    "else:\n",
    "    print(\"Sample has no mask.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zW6tx42LYVlA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample has no transform functions.\n"
     ]
    }
   ],
   "source": [
    "if sample.has_transform:\n",
    "    print(sample.transform)\n",
    "else:\n",
    "    print(\"Sample has no transform functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LR-LrjOwYVlA"
   },
   "source": [
    "#### Pattern\n",
    "\n",
    "The `pattern` mapping can be useful to glimpse on how data are arranged.\n",
    "The convention we use is the following:\n",
    "\n",
    "* \"b\" stands for \"batch size\"\n",
    "* \"c\" stands for \"number of channels\" (per node)\n",
    "* \"e\" stands for \"number edges\"\n",
    "* \"n\" stands for \"number of nodes\"\n",
    "* \"s\" stands for \"number of time steps\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4KeKgewEYVlA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 's n c',\n",
       " 'edge_index': '2 e',\n",
       " 'edge_weight': 'e',\n",
       " 'mask': 's n c',\n",
       " 'y': 's n c'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9j-pA8lCYVlA"
   },
   "source": [
    "### The SpatioTemporalDataModule\n",
    "\n",
    "Usually, before running an experiment there are two quite common preprocessing steps:\n",
    "\n",
    "* splitting the dataset into training/validation/test sets\n",
    "* data preprocessing (scaling/normalizing data, detrending)\n",
    "\n",
    "In `tsl`, these operations are carried out in the `tsl.data.SpatioTemporalDataModule`, which is based on `pytorch-lightning`'s data modules.\n",
    "\n",
    "Let's see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "3aGnkoCgYVlA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataModule(train_len=None, val_len=None, test_len=None, scalers=[data], batch_size=64)\n"
     ]
    }
   ],
   "source": [
    "from tsl.data import SpatioTemporalDataModule\n",
    "from tsl.data.preprocessing import StandardScaler\n",
    "\n",
    "scalers = {'data': StandardScaler(axis=(0, 1))}\n",
    "\n",
    "splitter = dataset.get_splitter(val_len=0.1, test_len=0.2)\n",
    "\n",
    "dm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset,\n",
    "    scalers=scalers,\n",
    "    splitter=splitter,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "229wC1LaYVlB"
   },
   "source": [
    " Eventually one could extend the base datamodule to add further processing in case it is needed.\n",
    "\n",
    "At this point, the `DataModule` object has not actually performed any processing yet (lazy approach).\n",
    "\n",
    "We can execute the preprocessing routines by calling `setup` method.\n",
    "\n",
    "Note that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "tMpX1zbfYVlB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpatioTemporalDataModule(train_len=5141, val_len=576, test_len=2884, scalers=[data], batch_size=64)\n"
     ]
    }
   ],
   "source": [
    "dm.setup()\n",
    "print(dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXQy8qMDYVlB"
   },
   "source": [
    "After `setup` has been called, the datamodule carries the following operations:\n",
    "\n",
    "1. Carries out the dataset splitting into training/validation/test sets according to the `splitter` argument.\n",
    "1. Fits all the `Scalers` on the training data in `dataset` corresponding to the scalers' keys.\n",
    "\n",
    "#### Scalers\n",
    "\n",
    "The `tsl.data.preprocessing` package offers several of the most common data normalization techniques under the `tsl.data.preprocessing.Scaler` interface.\n",
    "They adopt an API similar to `scikit-learn`'s scalers, with `fit`/`transform`/`fit_transform`/`inverse_transform` methods. Check the documentation for more details about this.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d60HdqXCYVlB"
   },
   "source": [
    "## Building a Model\n",
    "---\n",
    "\n",
    "In this section, we will see how to build a very simple Graph Neural Network for Spatiotemporal data.\n",
    "All the neural network code inside `tsl` is under the `tsl.nn` module.\n",
    "\n",
    "\n",
    "### The NN module\n",
    "\n",
    "The `tsl.nn` module is organized as follows:\n",
    "\n",
    "```\n",
    "tsl\n",
    "└── nn\n",
    "    ├── base\n",
    "    ├── blocks\n",
    "    ├── layers\n",
    "    ├── models\n",
    "    ├── metrics\n",
    "    ├── ops\n",
    "    └── utils\n",
    "```\n",
    "\n",
    "The 3 most important submodules in it are `layers`, `blocks`, and `models`, ordered by increasing level of abstraction.\n",
    "\n",
    "#### Layers\n",
    "\n",
    "A _layer_ is a basic building block for our neural networks. In simple words, a layer takes an input, performs one (or few) operations, and return a transformation of the input. Examples of layers are `DiffConv`, which implements [diffusion convolution](https://arxiv.org/abs/1707.01926), or `LayerNorm`.\n",
    "\n",
    "#### Blocks\n",
    "\n",
    "_blocks_ perform more complex transformations or combine several operations. We divide blocks into _encoders_, if they provide a representation of the input in a new space, and _decoders_, if they produce a meaningful output from a representation.\n",
    "\n",
    "#### Models\n",
    "\n",
    "We wrap a series of operations, represented by blocks and/or layers, in a _model_. A model is meant to takes as input a batch `SpatioTemporalDataset`'s items and return the desired output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQiMvBjGYVlC"
   },
   "source": [
    "Let's create a very simple model with a RNN encoder and a nonlinear GCN readout.\n",
    "To do so, we import `RNN` from the encoders and `GCNDecoder` from the decoders in the `tsl.nn.blocks` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ORL_KKbuYVlC"
   },
   "outputs": [],
   "source": [
    "from tsl.nn.blocks.encoders import RNN\n",
    "from tsl.nn.blocks.decoders import GCNDecoder\n",
    "\n",
    "\n",
    "class TimeThenSpaceModel(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 hidden_size,\n",
    "                 rnn_layers,\n",
    "                 gcn_layers,\n",
    "                 horizon):\n",
    "        super(TimeThenSpaceModel, self).__init__()\n",
    "\n",
    "        self.input_encoder = torch.nn.Linear(input_size, hidden_size)\n",
    "\n",
    "        self.encoder = RNN(input_size=hidden_size,\n",
    "                           hidden_size=hidden_size,\n",
    "                           n_layers=rnn_layers)\n",
    "\n",
    "        self.decoder = GCNDecoder(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=input_size,\n",
    "            horizon=horizon,\n",
    "            n_layers=gcn_layers\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        # x: [batches steps nodes channels]\n",
    "        x = self.input_encoder(x)\n",
    "\n",
    "        x = self.encoder(x, return_last_state=True)\n",
    "\n",
    "        return self.decoder(x, edge_index, edge_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fu_1-ojYVlC"
   },
   "source": [
    "Fine, we have a model and we have data, now let's train it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3uABycjYVlC"
   },
   "source": [
    "## Setting up training\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dxvEqv95YVlC"
   },
   "source": [
    "### The Predictor\n",
    "\n",
    "In `tsl`, inference engines are implemented as a [`LightningModule`](https://pytorch-lightning.readthedocs.io/en/latest/api/pytorch_lightning.core.LightningModule.html#pytorch_lightning.core.LightningModule). `tsl.predictors.Predictor` is a base class that can be extended to build more complex forecasting approaches.\n",
    "These modules are meant to wrap deep models in order to ease training and inference phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GULyga_lYVlD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/utilities/parsing.py:244: UserWarning: Attribute 'loss_fn' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss_fn'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "from tsl.nn.metrics.metrics import MaskedMAE, MaskedMAPE\n",
    "from tsl.predictors import Predictor\n",
    "\n",
    "loss_fn = MaskedMAE(compute_on_step=True)\n",
    "\n",
    "metrics = {'mae': MaskedMAE(compute_on_step=False),\n",
    "           'mape': MaskedMAPE(compute_on_step=False),\n",
    "           'mae_at_15': MaskedMAE(compute_on_step=False, at=2),  # `2` indicated the third time step,\n",
    "                                                                 # which correspond to 15 minutes ahead\n",
    "           'mae_at_30': MaskedMAE(compute_on_step=False, at=5),\n",
    "           'mae_at_60': MaskedMAE(compute_on_step=False, at=11), }\n",
    "\n",
    "model_kwargs = {\n",
    "    'input_size': dm.n_channels,  # 1 channel\n",
    "    'horizon': dm.horizon,  # 12, the number of steps ahead to forecast\n",
    "    'hidden_size': 32,\n",
    "    'rnn_layers': 1,\n",
    "    'gcn_layers': 2\n",
    "}\n",
    "\n",
    "# setup predictor\n",
    "predictor = Predictor(\n",
    "    model_class=TimeThenSpaceModel,\n",
    "    model_kwargs=model_kwargs,\n",
    "    optim_class=torch.optim.Adam,\n",
    "    optim_kwargs={'lr': 0.001},\n",
    "    loss_fn=loss_fn,\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-34Ntg3lYVlD"
   },
   "source": [
    "Now let's finalize the last details. We make use of [TensorBoard](https://www.tensorflow.org/tensorboard/) to log and visualize metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "a3zdVgNRYVlD"
   },
   "outputs": [],
   "source": [
    "# from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "# logger = TensorBoardLogger(save_dir=\"logs\", name=\"tsl_intro\", version=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "logger = CSVLogger(save_dir='prova' , name='savedata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4IU2vFKYVlD"
   },
   "outputs": [],
   "source": [
    "\n",
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1b57xoTYVlD"
   },
   "source": [
    "We let `pytorch_lightning.Trainer` handle the dirty work for us. We can directly pass the datamodule to the trainer for fitting.\n",
    "\n",
    "If this is the case, the trainer will call the `setup` method, and then load train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "WSJLVCaFYVlD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/callbacks/model_checkpoint.py:608: UserWarning: Checkpoint directory /home/lorenzo/PycharmProjects/gdl_air_quality/code/utility notebooks/logs exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE          | 0     \n",
      "1 | train_metrics | MetricCollection   | 0     \n",
      "2 | val_metrics   | MetricCollection   | 0     \n",
      "3 | test_metrics  | MetricCollection   | 0     \n",
      "4 | model         | TimeThenSpaceModel | 12.0 K\n",
      "-----------------------------------------------------\n",
      "12.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "12.0 K    Total params\n",
      "0.048     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 89/89 [10:27<00:00,  7.05s/it, loss=26.5, v_num=1, val_mae=25.10, val_mae_at_15=18.90, val_mae_at_30=25.80, val_mae_at_60=33.30, val_mape=0.620, train_mae=26.30, train_mae_at_15=20.60, train_mae_at_30=27.30, train_mae_at_60=33.40, train_mape=0.616]   \n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='logs',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=3,\n",
    "                     logger=logger,\n",
    "                     gpus=1 if torch.cuda.is_available() else None,\n",
    "                     limit_train_batches=100,\n",
    "                     callbacks=[checkpoint_callback])\n",
    "\n",
    "trainer.fit(predictor, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bAHFLAEYVlE"
   },
   "source": [
    "## Testing\n",
    "---\n",
    "\n",
    "\n",
    "Now let's see how the trained model behaves on new unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "aV-v6EfCYVlE"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/anaconda3/envs/GDL/lib/python3.9/site-packages/pytorch_lightning-1.6.0-py3.9.egg/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 46/46 [00:46<00:00,  1.01s/it]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           24.076353073120117\n",
      "        test_mae            24.635517120361328\n",
      "     test_mae_at_15         19.228456497192383\n",
      "     test_mae_at_30         25.976608276367188\n",
      "     test_mae_at_60          31.25102424621582\n",
      "        test_mape           0.6429881453514099\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "predictor.load_model(checkpoint_callback.best_model_path)\n",
    "predictor.freeze()\n",
    "\n",
    "performance = trainer.test(predictor, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRd_FMpyYVlE"
   },
   "source": [
    "Cool! We succeeded in creating first a simple, yet effective, SpatioTemporal model!\n",
    "\n",
    "We are now __tsl ninjas__. We learned how to:\n",
    "\n",
    "* Load benchmark datasets\n",
    "* Organize data for processing\n",
    "* Preprocess the data\n",
    "* Build a Spatiotemporal GNN\n",
    "* Train and evaluate the model\n",
    "\n",
    "We hope you enjoyed this introduction to `tsl`, do not hesitate to contact us if you have any question or problem while using it.\n",
    "\n",
    "The tsl team.\n",
    "\n",
    "🧡"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "a_gentle_introduction_to_tsl.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "680e81d386bdd33f7a9a9653c5e155acb4122dc6ba1be0a86a256d82ab40669b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('GDL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}